import streamlit as st
from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain_google_genai import GoogleGenerativeAI
from langchain.memory import ConversationBufferWindowMemory
from langchain.prompts import PromptTemplate
import os
import pickle
import json
from datetime import datetime
import requests
import tempfile
import glob
from pathlib import Path
from dotenv import load_dotenv
import base64

def get_base64_of_image(path):
    """Convert image to base64 string"""
    try:
        with open(path, "rb") as img_file:
            return base64.b64encode(img_file.read()).decode()
    except Exception as e:
        return ""

# Cáº¥u hÃ¬nh trang
st.set_page_config(
    page_title="Chatbot TÆ° Váº¥n - Äáº¡i há»c Luáº­t TPHCM",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS tá»‘i Æ°u
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
    
    * { font-family: 'Inter', sans-serif; }
    
    .main-header {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        padding: 2rem;
        border-radius: 20px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(30, 60, 114, 0.3);
    }
    
    .main-header h1 {
        font-size: 2.2rem;
        font-weight: 700;
        margin: 0.5rem 0;
    }
    
    .chat-message {
        padding: 1.5rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
    }
    
    .category-badge {
        display: inline-block;
        padding: 0.4rem 0.8rem;
        border-radius: 15px;
        font-size: 0.75rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
    }
    
    .badge-tuyensinh { background: #e3f2fd; color: #1565c0; }
    .badge-hocphi { background: #e8f5e8; color: #2e7d32; }
    .badge-chuongtrinh { background: #f3e5f5; color: #6a1b9a; }
    
    .info-card {
        background: linear-gradient(135deg, #fff3e0 0%, #ffe0b2 100%);
        border: 1px solid #ffb74d;
        border-radius: 15px;
        padding: 1.5rem;
        margin: 1rem 0;
    }
    
    .footer {
        background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        margin-top: 3rem;
        text-align: center;
    }
    
    .stButton>button {
        background: linear-gradient(135deg, #2196f3 0%, #1976d2 100%);
        color: white;
        border: none;
        border-radius: 10px;
        padding: 0.5rem 1rem;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    
    .stButton>button:hover {
        background: linear-gradient(135deg, #1976d2 0%, #1565c0 100%);
        transform: translateY(-2px);
    }
</style>
""", unsafe_allow_html=True)

# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()

# Äá»ŒC API KEY Tá»ª SECRETS TRÆ¯á»šC, SAU ÄÃ“ Má»šI Äáº¾N .env
try:
    gemini_api_key = st.secrets["GEMINI_API_KEY"]
except:
    gemini_api_key = os.getenv("GEMINI_API_KEY")

try:
    GDRIVE_VECTORSTORE_ID = st.secrets["GDRIVE_VECTORSTORE_ID"]
except:
    GDRIVE_VECTORSTORE_ID = os.getenv("GDRIVE_VECTORSTORE_ID")

try:
    GDRIVE_METADATA_ID = st.secrets["GDRIVE_METADATA_ID"]
except:
    GDRIVE_METADATA_ID = os.getenv("GDRIVE_METADATA_ID")

# Cáº¥u hÃ¬nh Ä‘Æ°á»ng dáº«n
DOCUMENTS_PATH = "documents"
VECTORSTORE_PATH = "vectorstore"

for path in [DOCUMENTS_PATH, VECTORSTORE_PATH]:
    Path(path).mkdir(exist_ok=True)

# Template prompt
COUNSELING_PROMPT_TEMPLATE = """
Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n tuyá»ƒn sinh TrÆ°á»ng Äáº¡i há»c Luáº­t ThÃ nh phá»‘ Há»“ ChÃ­ Minh.

THÃ”NG TIN LIÃŠN Há»† CHÃNH THá»¨C:
- Hotline tuyá»ƒn sinh: 1900 5555 14 hoáº·c 0879 5555 14
- Email: tuyensinh@hcmulaw.edu.vn
- Äiá»‡n thoáº¡i: (028) 39400 989
- Äá»‹a chá»‰: 2 Nguyá»…n Táº¥t ThÃ nh, PhÆ°á»ng 12, Quáº­n 4, TP.HCM
- Website: www.hcmulaw.edu.vn

NguyÃªn táº¯c tráº£ lá»i:
1. ThÃ¢n thiá»‡n, chuyÃªn nghiá»‡p
2. Cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c vá» Äáº¡i há»c Luáº­t TPHCM
3. KHÃ”NG sá»­ dá»¥ng placeholder, luÃ´n dÃ¹ng thÃ´ng tin liÃªn há»‡ cá»¥ thá»ƒ á»Ÿ trÃªn
4. Náº¿u khÃ´ng cháº¯c cháº¯n, khuyáº¿n khÃ­ch liÃªn há»‡ trá»±c tiáº¿p

ThÃ´ng tin tham kháº£o: {context}
Lá»‹ch sá»­ há»™i thoáº¡i: {chat_history}
CÃ¢u há»i: {question}

Tráº£ lá»i (tiáº¿ng Viá»‡t):
"""

@st.cache_resource
def load_embeddings():
    return HuggingFaceEmbeddings(
        model_name="keepitreal/vietnamese-sbert",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )

embeddings = load_embeddings()

def download_from_gdrive_direct(file_id, output_path):
    """
    Download file tá»« Google Drive báº±ng requests (khÃ´ng dÃ¹ng gdown)
    File pháº£i Ä‘Æ°á»£c share cÃ´ng khai: Anyone with the link
    """
    try:
        # URL download trá»±c tiáº¿p tá»« GDrive
        url = f"https://drive.google.com/uc?export=download&id={file_id}"
        
        session = requests.Session()
        response = session.get(url, stream=True)
        
        # Xá»­ lÃ½ virus scan warning cá»§a GDrive (file lá»›n)
        for key, value in response.cookies.items():
            if key.startswith('download_warning'):
                params = {'export': 'download', 'id': file_id, 'confirm': value}
                response = session.get(url, params=params, stream=True)
                break
        
        # LÆ°u file
        with open(output_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=32768):
                if chunk:
                    f.write(chunk)
        
        return True
        
    except Exception as e:
        st.warning(f"âš ï¸ KhÃ´ng thá»ƒ táº£i tá»« GDrive: {e}")
        return False

def get_document_files():
    """Láº¥y danh sÃ¡ch file trong documents"""
    files = []
    for ext in ['*.pdf', '*.docx', '*.txt']:
        files.extend(glob.glob(os.path.join(DOCUMENTS_PATH, '**', ext), recursive=True))
    return files

def get_file_hash(file_path):
    """Táº¡o hash cho file"""
    stat = os.stat(file_path)
    return f"{stat.st_mtime}_{stat.st_size}"

def load_cached_vectorstore():
    """Load vector store tá»« Google Drive"""
    if not GDRIVE_VECTORSTORE_ID or not GDRIVE_METADATA_ID:
        st.info("â„¹ï¸ ChÆ°a cáº¥u hÃ¬nh Google Drive, sá»­ dá»¥ng xá»­ lÃ½ local")
        return None, {}
    
    temp_dir = tempfile.mkdtemp()
    vectorstore_path = os.path.join(temp_dir, "vectorstore.pkl")
    metadata_path = os.path.join(temp_dir, "metadata.json")
    
    try:
        # Download báº±ng requests thay vÃ¬ gdown
        if not download_from_gdrive_direct(GDRIVE_VECTORSTORE_ID, vectorstore_path):
            return None, {}
        if not download_from_gdrive_direct(GDRIVE_METADATA_ID, metadata_path):
            return None, {}
        
        with open(vectorstore_path, 'rb') as f:
            vectorstore = pickle.load(f)
        
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        
        # Cleanup
        os.remove(vectorstore_path)
        os.remove(metadata_path)
        os.rmdir(temp_dir)
        
        st.success("âœ… ÄÃ£ load vectorstore tá»« Google Drive")
        return vectorstore, metadata
        
    except Exception as e:
        st.warning(f"âš ï¸ KhÃ´ng thá»ƒ load tá»« GDrive: {e}")
        # Cleanup náº¿u cÃ³ lá»—i
        try:
            if os.path.exists(vectorstore_path):
                os.remove(vectorstore_path)
            if os.path.exists(metadata_path):
                os.remove(metadata_path)
            if os.path.exists(temp_dir):
                os.rmdir(temp_dir)
        except:
            pass
        return None, {}

def process_documents(file_paths):
    """Xá»­ lÃ½ documents"""
    documents = []
    processed = []
    failed = []
    
    for file_path in file_paths:
        try:
            ext = Path(file_path).suffix.lower()
            
            if ext == ".pdf":
                loader = PyPDFLoader(file_path)
            elif ext == ".docx":
                loader = Docx2txtLoader(file_path)
            elif ext == ".txt":
                loader = TextLoader(file_path, encoding='utf-8')
            else:
                failed.append(f"{file_path} (khÃ´ng há»— trá»£)")
                continue
            
            docs = loader.load()
            for doc in docs:
                doc.metadata['source_file'] = os.path.basename(file_path)
                doc.metadata['processed_time'] = datetime.now().isoformat()
            
            documents.extend(docs)
            processed.append(file_path)
            
        except Exception as e:
            failed.append(f"{file_path} ({str(e)})")
    
    return documents, processed, failed

def create_vector_store(documents):
    """Táº¡o vector store"""
    if not documents:
        return None
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=['\n\n', '\n', '.', '!', '?', ';', ':', ' ']
    )
    texts = text_splitter.split_documents(documents)
    texts = [t for t in texts if len(t.page_content.strip()) > 50]
    
    if not texts:
        return None
    
    return FAISS.from_documents(texts, embeddings)

@st.cache_resource
def initialize_vectorstore():
    """Khá»Ÿi táº¡o vectorstore"""
    # Thá»­ load tá»« GDrive trÆ°á»›c
    vectorstore, metadata = load_cached_vectorstore()
    if vectorstore:
        return vectorstore, metadata.get('stats', {})
    
    # Náº¿u khÃ´ng cÃ³ GDrive, xá»­ lÃ½ local files
    st.info("â„¹ï¸ Äang xá»­ lÃ½ tÃ i liá»‡u local...")
    current_files = get_document_files()
    
    if not current_files:
        st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y file nÃ o trong thÆ° má»¥c documents")
        return None, {}
    
    with st.spinner("ğŸ”„ Äang xá»­ lÃ½ tÃ i liá»‡u..."):
        documents, processed, failed = process_documents(current_files)
        
        if not documents:
            st.error("âŒ KhÃ´ng thá»ƒ xá»­ lÃ½ file nÃ o")
            return None, {}
        
        vectorstore = create_vector_store(documents)
        
        if vectorstore:
            stats = {
                'total_files': len(current_files),
                'processed_files': len(processed),
                'failed_files': len(failed),
                'total_chunks': vectorstore.index.ntotal,
                'last_updated': datetime.now().isoformat()
            }
            st.success(f"âœ… ÄÃ£ xá»­ lÃ½ {len(processed)} files thÃ nh cÃ´ng!")
            return vectorstore, stats
    
    return None, {}

def classify_question(question):
    """PhÃ¢n loáº¡i cÃ¢u há»i"""
    question_lower = question.lower()
    
    categories = {
        "Tuyá»ƒn sinh": ["tuyá»ƒn sinh", "Ä‘Äƒng kÃ½", "há»“ sÆ¡", "Ä‘iá»ƒm chuáº©n", "xÃ©t tuyá»ƒn"],
        "Há»c phÃ­": ["há»c phÃ­", "chi phÃ­", "miá»…n giáº£m", "há»c bá»•ng"],
        "ChÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o": ["chÆ°Æ¡ng trÃ¬nh", "mÃ´n há»c", "tÃ­n chá»‰", "ngÃ nh"],
    }
    
    for category, keywords in categories.items():
        if any(kw in question_lower for kw in keywords):
            return category
    return "KhÃ¡c"

def get_category_badge(category):
    """Táº¡o badge cho category"""
    badge_map = {
        "Tuyá»ƒn sinh": "badge-tuyensinh",
        "Há»c phÃ­": "badge-hocphi",
        "ChÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o": "badge-chuongtrinh"
    }
    badge_class = badge_map.get(category, "badge-tuyensinh")
    return f'<span class="category-badge {badge_class}">{category}</span>'

def create_conversational_chain(vector_store, llm):
    """Táº¡o chain"""
    prompt = PromptTemplate(
        template=COUNSELING_PROMPT_TEMPLATE,
        input_variables=["context", "chat_history", "question"]
    )
    
    memory = ConversationBufferWindowMemory(
        k=5,
        memory_key="chat_history",
        return_messages=True,
        output_key="answer"
    )
    
    return ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vector_store.as_retriever(search_kwargs={"k": 5}),
        memory=memory,
        return_source_documents=True,
        combine_docs_chain_kwargs={"prompt": prompt}
    )

@st.cache_resource
def get_gemini_llm():
    """
    Khá»Ÿi táº¡o Gemini LLM vá»›i tÃªn model CHÃNH XÃC
    
    QUAN TRá»ŒNG: langchain-google-genai chá»‰ há»— trá»£:
    - gemini-pro (stable)
    - gemini-1.5-pro-latest 
    - gemini-1.5-flash-latest
    
    KHÃ”NG há»— trá»£: gemini-1.5-flash (thiáº¿u -latest)
    """
    if not gemini_api_key:
        st.error("âŒ Thiáº¿u GEMINI_API_KEY!")
        st.stop()
    
    try:
        # Thá»­ model gemini-pro trÆ°á»›c (á»•n Ä‘á»‹nh nháº¥t)
        llm = GoogleGenerativeAI(
            model="gemini-pro",  # Model á»•n Ä‘á»‹nh nháº¥t
            google_api_key=gemini_api_key,
            temperature=0.3,
            max_output_tokens=2000
        )
        
        # Test model
        llm.invoke("Hello")
        st.success("âœ… ÄÃ£ káº¿t ná»‘i Gemini Pro")
        return llm
        
    except Exception as e:
        st.error(f"âŒ Lá»—i káº¿t ná»‘i Gemini: {e}")
        st.info("ğŸ’¡ HÃ£y kiá»ƒm tra API key táº¡i: https://makersuite.google.com/app/apikey")
        st.stop()

def answer_from_external_api(prompt, llm, question_category):
    """Tráº£ lá»i tá»« API"""
    enhanced_prompt = f"""
Báº¡n lÃ  chuyÃªn gia tÆ° váº¥n {question_category.lower()} cá»§a Äáº¡i há»c Luáº­t TPHCM.

THÃ”NG TIN LIÃŠN Há»† (Báº®T BUá»˜C Sá»¬ Dá»¤NG):
- Hotline: 1900 5555 14 hoáº·c 0879 5555 14
- Email: tuyensinh@hcmulaw.edu.vn
- Äiá»‡n thoáº¡i: (028) 39400 989
- Äá»‹a chá»‰: 2 Nguyá»…n Táº¥t ThÃ nh, PhÆ°á»ng 12, Quáº­n 4, TP.HCM
- Website: www.hcmulaw.edu.vn

CÃ¢u há»i: {prompt}

QUY Táº®C:
- KHÃ”NG dÃ¹ng placeholder nhÆ° [Sá»‘ Ä‘iá»‡n thoáº¡i], [Email]
- LuÃ´n dÃ¹ng thÃ´ng tin cá»¥ thá»ƒ á»Ÿ trÃªn
- Káº¿t thÃºc báº±ng thÃ´ng tin liÃªn há»‡ náº¿u cáº§n

Tráº£ lá»i thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p:
"""
    
    try:
        response = llm.invoke(enhanced_prompt)
        
        # Thay tháº¿ placeholder cÃ²n sÃ³t
        replacements = {
            "[Sá»‘ Ä‘iá»‡n thoáº¡i": "1900 5555 14 hoáº·c 0879 5555 14",
            "[Email": "tuyensinh@hcmulaw.edu.vn",
            "[Website": "www.hcmulaw.edu.vn"
        }
        
        for placeholder, actual in replacements.items():
            if placeholder in response:
                response = response.replace(placeholder + "]", actual)
        
        return response
        
    except Exception as e:
        return f"""
Xin lá»—i, há»‡ thá»‘ng gáº·p sá»± cá»‘. Vui lÃ²ng liÃªn há»‡:

ğŸ“ Hotline: 1900 5555 14 hoáº·c 0879 5555 14
ğŸ“§ Email: tuyensinh@hcmulaw.edu.vn
ğŸŒ Website: www.hcmulaw.edu.vn
ğŸ“ Äá»‹a chá»‰: 2 Nguyá»…n Táº¥t ThÃ nh, P.12, Q.4, TP.HCM

Lá»—i: {str(e)}
"""

def display_quick_questions():
    """Hiá»ƒn thá»‹ cÃ¢u há»i gá»£i Ã½"""
    st.markdown("### ğŸ’¡ CÃ¢u há»i thÆ°á»ng gáº·p")
    
    questions = [
        "ğŸ“ Thá»§ tá»¥c Ä‘Äƒng kÃ½ xÃ©t tuyá»ƒn?",
        "ğŸ’° Há»c phÃ­ cá»§a trÆ°á»ng?",
        "ğŸ“š CÃ¡c ngÃ nh há»c?",
        "ğŸ  TrÆ°á»ng cÃ³ kÃ½ tÃºc xÃ¡ khÃ´ng?",
        "ğŸ“ CÆ¡ há»™i viá»‡c lÃ m?",
        "ğŸ“ ThÃ´ng tin liÃªn há»‡?"
    ]
    
    cols = st.columns(2)
    for i, q in enumerate(questions):
        with cols[i % 2]:
            if st.button(q, key=f"q_{i}", use_container_width=True):
                clean_q = q.split(" ", 1)[1]
                st.session_state.messages.append({"role": "user", "content": clean_q})
                st.session_state.process_question = clean_q
                st.rerun()

def main():
    # Kiá»ƒm tra API key
    if not gemini_api_key:
        st.error("âš ï¸ **Thiáº¿u GEMINI_API_KEY!**")
        st.info("""
        **CÃ¡ch cáº¥u hÃ¬nh:**
        1. VÃ o Settings â†’ Secrets trÃªn Streamlit Cloud
        2. ThÃªm:
        ```
        GEMINI_API_KEY = "your-api-key"
        ```
        3. Láº¥y API key táº¡i: https://makersuite.google.com/app/apikey
        """)
        st.stop()
    
    # Khá»Ÿi táº¡o session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "first_visit" not in st.session_state:
        st.session_state.first_visit = True

    # Header
    logo_base64 = get_base64_of_image("logo.jpg")
    st.markdown(f"""
    <div class="main-header">
        {f'<img src="data:image/jpg;base64,{logo_base64}" style="width:80px;border-radius:50%;margin-bottom:1rem;">' if logo_base64 else ''}
        <h1>ğŸ¤– Chatbot TÆ° Váº¥n Tuyá»ƒn Sinh</h1>
        <h3>TrÆ°á»ng Äáº¡i há»c Luáº­t TP. Há»“ ChÃ­ Minh</h3>
        <p>ğŸ’¬ Há»— trá»£ 24/7 | ğŸ“ TÆ° váº¥n chuyÃªn nghiá»‡p</p>
    </div>
    """, unsafe_allow_html=True)

    # Sidebar
    with st.sidebar:
        st.markdown("### âš™ï¸ CÃ i Ä‘áº·t")
        
        # ThÃ´ng tin há»‡ thá»‘ng
        with st.expander("ğŸ“Š Tráº¡ng thÃ¡i há»‡ thá»‘ng", expanded=False):
            st.success("âœ… Gemini API: ÄÃ£ káº¿t ná»‘i")
            st.info(f"ğŸ“ Documents: {len(get_document_files())} files")
            
            if GDRIVE_VECTORSTORE_ID:
                st.info("â˜ï¸ Google Drive: ÄÃ£ cáº¥u hÃ¬nh")
            else:
                st.warning("âš ï¸ Google Drive: ChÆ°a cáº¥u hÃ¬nh")
        
        # HÆ°á»›ng dáº«n cáº¥u hÃ¬nh GDrive
        with st.expander("ğŸ“– HÆ°á»›ng dáº«n Google Drive", expanded=False):
            st.markdown("""
            **Äá»ƒ sá»­ dá»¥ng Google Drive:**
            
            1. Upload file `vectorstore.pkl` vÃ  `metadata.json` lÃªn GDrive
            2. Click chuá»™t pháº£i â†’ Share â†’ Anyone with the link
            3. Copy File ID tá»« URL (pháº§n sau `/d/` vÃ  trÆ°á»›c `/view`)
            4. ThÃªm vÃ o Secrets:
            ```
            GDRIVE_VECTORSTORE_ID = "file-id-1"
            GDRIVE_METADATA_ID = "file-id-2"
            ```
            """)
        
        # NÃºt lÃ m má»›i
        if st.button("ğŸ”„ LÃ m má»›i dá»¯ liá»‡u", use_container_width=True):
            st.cache_resource.clear()
            st.rerun()
        
        st.markdown("---")
        st.markdown("""
        ### ğŸ“ LiÃªn há»‡
        **Hotline:** 1900 5555 14  
        **Email:** tuyensinh@hcmulaw.edu.vn  
        **Web:** www.hcmulaw.edu.vn
        """)

    # Khá»Ÿi táº¡o vectorstore vÃ  LLM
    with st.spinner("ğŸ”„ Äang khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng..."):
        vectorstore, stats = initialize_vectorstore()
        llm = get_gemini_llm()
        chain = create_conversational_chain(vectorstore, llm) if vectorstore else None

    # Hiá»ƒn thá»‹ cÃ¢u há»i gá»£i Ã½ náº¿u lÃ  láº§n Ä‘áº§u
    if not st.session_state.messages and st.session_state.first_visit:
        display_quick_questions()
        
        st.markdown("""
        <div class="info-card">
            <h4>ğŸ’¡ HÆ°á»›ng dáº«n sá»­ dá»¥ng:</h4>
            <ul>
                <li>ğŸ¯ Chá»n cÃ¢u há»i gá»£i Ã½ hoáº·c nháº­p cÃ¢u há»i cá»§a báº¡n</li>
                <li>ğŸ’¬ Äáº·t cÃ¢u há»i cá»¥ thá»ƒ Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n chÃ­nh xÃ¡c</li>
                <li>ğŸ“ LiÃªn há»‡ trá»±c tiáº¿p náº¿u cáº§n há»— trá»£ kháº©n cáº¥p</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

    # Hiá»ƒn thá»‹ lá»‹ch sá»­ chat
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            if msg["role"] == "assistant" and "category" in msg:
                st.markdown(get_category_badge(msg["category"]), unsafe_allow_html=True)
            st.markdown(msg["content"])

    # Xá»­ lÃ½ input
    prompt = None
    if hasattr(st.session_state, 'process_question'):
        prompt = st.session_state.process_question
        del st.session_state.process_question
    else:
        prompt = st.chat_input("ğŸ’¬ HÃ£y Ä‘áº·t cÃ¢u há»i...")

    if prompt:
        st.session_state.first_visit = False
        
        # Hiá»ƒn thá»‹ cÃ¢u há»i
        with st.chat_message("user"):
            st.markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # PhÃ¢n loáº¡i vÃ  tráº£ lá»i
        category = classify_question(prompt)
        
        with st.chat_message("assistant"):
            st.markdown(get_category_badge(category), unsafe_allow_html=True)
            
            with st.spinner("ğŸ¤” Äang suy nghÄ©..."):
                try:
                    if chain:
                        response = chain({"question": prompt})
                        answer = response["answer"]
                    else:
                        answer = answer_from_external_api(prompt, llm, category)
                    
                    st.markdown(answer)
                    
                except Exception as e:
                    answer = f"""
âŒ **Lá»—i há»‡ thá»‘ng**

Vui lÃ²ng liÃªn há»‡:
ğŸ“ Hotline: 1900 5555 14 hoáº·c 0879 5555 14
ğŸ“§ Email: tuyensinh@hcmulaw.edu.vn

Lá»—i: {str(e)}
"""
                    st.error(answer)

            st.session_state.messages.append({
                "role": "assistant",
                "content": answer,
                "category": category
            })

    # Footer
    st.markdown("---")
    st.markdown("""
    <div class="footer">
        <h4>ğŸ›ï¸ TrÆ°á»ng Äáº¡i há»c Luáº­t TP. Há»“ ChÃ­ Minh</h4>
        <p>ğŸ“ 2 Nguyá»…n Táº¥t ThÃ nh, PhÆ°á»ng 12, Quáº­n 4, TP.HCM</p>
        <p>ğŸ“ Hotline: 1900 5555 14 | Email: tuyensinh@hcmulaw.edu.vn</p>
        <p>ğŸŒ www.hcmulaw.edu.vn | ğŸ“˜ facebook.com/hcmulaw</p>
        <p style="margin-top:1rem;opacity:0.8;font-size:0.85em;">
            ğŸ¤– Chatbot v2.1 | PhÃ¡t triá»ƒn bá»Ÿi Lvphung - CNTT
        </p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
